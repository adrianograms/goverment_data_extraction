{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/10 20:32:59 WARN Utils: Your hostname, Ubuntu-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/10/10 20:32:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/10 20:33:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Extraction_Data\")\\\n",
    "        .config(\"spark.driver.extraClassPath\", \"/home/adriano/Documentos/airflow/jdbc/postgresql-42.7.4.jar\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_year = datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datetime.now().year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "ano_inicial = 2023\n",
    "ano_final = 2024\n",
    "for ano in range(int(ano_inicial), int(ano_final) + 1):\n",
    "    print(ano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024\n"
     ]
    }
   ],
   "source": [
    "ano_inicial = current_year\n",
    "ano_final = current_year\n",
    "\n",
    "dif_anos = (ano_final - ano_inicial) + 1\n",
    "for i in range(dif_anos):\n",
    "    print(ano_inicial + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- autorEmenda: string (nullable = true)\n",
      " |-- codigoAmparoLegal: long (nullable = true)\n",
      " |-- descricaoEmpenho: string (nullable = true)\n",
      " |-- fonteRecurso: string (nullable = true)\n",
      " |-- idProjetoInvestimento: string (nullable = true)\n",
      " |-- informacoesComplementares: string (nullable = true)\n",
      " |-- localEntrega: string (nullable = true)\n",
      " |-- naturezaDespesa: string (nullable = true)\n",
      " |-- nomeEsferaOrcamentaria: string (nullable = true)\n",
      " |-- nomeFavorecido: string (nullable = true)\n",
      " |-- nomeTipoEmpenho: string (nullable = true)\n",
      " |-- nrPtres: string (nullable = true)\n",
      " |-- numeroNotaEmpenhoGerada: string (nullable = true)\n",
      " |-- numeroProcesso: string (nullable = true)\n",
      " |-- pagina: long (nullable = true)\n",
      " |-- planoInterno: string (nullable = true)\n",
      " |-- planoOrcamentario: string (nullable = true)\n",
      " |-- resultadoPrimario: string (nullable = true)\n",
      " |-- tamanhoDaPagina: long (nullable = true)\n",
      " |-- tipoCredito: string (nullable = true)\n",
      " |-- ugEmitente: string (nullable = true)\n",
      " |-- ugResponsavel: long (nullable = true)\n",
      " |-- unidadeOrcamentaria: string (nullable = true)\n",
      " |-- valorEmpenho: double (nullable = true)\n",
      " |-- nomeArquivo: string (nullable = false)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import input_file_name, transform, col, substring\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "origin = '/home/adriano/Documentos/airflow/database/dest/bronze/execucao-financeira'\n",
    "process_all = True\n",
    "ano_final = current_year\n",
    "ano_inicial = current_year\n",
    "\n",
    "\n",
    "if process_all == False:\n",
    "    origin_file = origin + '/' + str(ano_inicial)+ '.json'\n",
    "    df = spark.read.json(origin_file)\n",
    "elif process_all == True:\n",
    "    origin_file = origin + '/*.json'\n",
    "    df = spark.read.json(origin_file) \n",
    "    df = df.withColumn('nomeArquivo',substring(input_file_name(),-9,4))\n",
    "\n",
    "\n",
    "#print(df.show())\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/10 20:33:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/10/10 20:33:16 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjdbc:postgresql://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost_dw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport_dw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatabase_dw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_dw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m: password_dw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver\u001b[39m\u001b[38;5;124m\"\u001b[39m: driver}\n\u001b[0;32m---> 18\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjdbc\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstg_execucao_financeira\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "dotenv_path = Path('/home/adriano/Documentos/airflow/.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "user_dw = os.getenv('USER_DW')\n",
    "password_dw = os.getenv('PASSWORD_DW')\n",
    "host_dw = os.getenv('HOST_DW')\n",
    "database_dw = os.getenv('DATABASE_DW')\n",
    "port_dw = os.getenv('PORT_DW')\n",
    "driver = \"org.postgresql.Driver\"\n",
    "\n",
    "mode = \"overwrite\"\n",
    "url = f'jdbc:postgresql://{host_dw}:{port_dw}/{database_dw}'\n",
    "properties = {\"user\": user_dw, \"password\": password_dw, \"driver\": driver}\n",
    "df.write.jdbc(url=url, table='stg_execucao_financeira', mode=mode, properties=properties)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'input_file_name()'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = \"teste\"\n",
    "teste[:-1]\n",
    "\n",
    "input_file_name()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
